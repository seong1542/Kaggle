{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20174327_유승연_딥러닝(최고점X)ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoFumGmUspVP",
        "outputId": "37e7071c-579a-4c9d-d340-bc35cd8e0ea2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "filepath = '/content/gdrive/My Drive/tabular_playground/'\n",
        "train = pd.read_csv(filepath+'train.csv')\n",
        "test=pd.read_csv(filepath+'test.csv')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnUVLuNtsrJo",
        "outputId": "cb7f93fb-cc01-4922-8def-34b50d059975"
      },
      "source": [
        "cat_cols = [feature for feature in train.columns if 'cat' in feature]  #cat으로 시작하는 열 이름 모으기\n",
        "num_cols=[num for num in train.columns if 'cont' in num]    #cont로 시작하는 열 이름 모으기\n",
        "print(cat_cols)\n",
        "print(num_cols)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9']\n",
            "['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKeM3T03sy-J"
      },
      "source": [
        "# cat에 있던 알파벳 -> 숫자로 변환\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for i in cat_cols:\n",
        "  le = LabelEncoder()\n",
        "  train[i] = le.fit_transform(train[i])\n",
        "  test[i]=le.fit_transform(test[i])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35wbkSAVs2J-"
      },
      "source": [
        "# 인코딩 시킨 데이터들을 train과 test 셋으로 다시 나눈다.\n",
        "train.drop('id', axis=1, inplace=True)\n",
        "test.drop('id', axis=1, inplace=True)\n",
        "y_train = train['target']\n",
        "X_train = train.drop('target', axis=1)\n",
        "X_test = test"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUfHmN8Hs4jM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state = 0,shuffle=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNRvwxTHs6Bz"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_CBsXOtCe6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "# 1. hidden unit을 점차 줄여가는 형식으로 해봄.\n",
        "activ_ = 'relu'\n",
        "h_units = 36\n",
        "n_inputs=24\n",
        "\n",
        "def dnn_model():\n",
        "  model=Sequential()\n",
        "\n",
        "  #hidden layer #1\n",
        "  model.add(Dense(units = (h_units+300), input_dim = n_inputs))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #2\n",
        "  model.add(Dense(units = (h_units+200)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #3\n",
        "  model.add(Dense(units = (h_units+150)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #4\n",
        "  model.add(Dense(units = (h_units+100)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #5\n",
        "  model.add(Dense(units = (h_units+50)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #6\n",
        "  model.add(Dense(units = (h_units+25)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #7\n",
        "  model.add(Dense(units = h_units))\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #output layer\n",
        "  model.add(Dense(units = 1))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8M9IqxsbtgK9",
        "outputId": "3e13dfd0-2140-422e-82ce-4f64251835b4"
      },
      "source": [
        "model =dnn_model()\n",
        "model.summary()\n",
        "opti = tf.keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(optimizer = opti,loss = 'mean_squared_error',metrics=[tf.keras.metrics.MeanSquaredError()])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 336)               8400      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 336)               1344      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 336)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 236)               79532     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 236)               944       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 236)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 186)               44082     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 186)               744       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 186)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 136)               25432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 136)               544       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 136)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 86)                11782     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 86)                344       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 86)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 61)                5307      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 61)                244       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 61)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 36)                2232      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 37        \n",
            "=================================================================\n",
            "Total params: 180,968\n",
            "Trainable params: 178,886\n",
            "Non-trainable params: 2,082\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QpY3BHbtwuy",
        "outputId": "66e65e38-a61c-4a9c-d135-79e33a0386b9"
      },
      "source": [
        "hist = model.fit(X_train, y_train, epochs=100, verbose=True,batch_size=32, validation_data=(X_valid,y_valid),shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.8025 - mean_squared_error: 0.8025 - val_loss: 0.7923 - val_mean_squared_error: 0.7923\n",
            "Epoch 2/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7715 - mean_squared_error: 0.7715 - val_loss: 0.7636 - val_mean_squared_error: 0.7636\n",
            "Epoch 3/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7609 - mean_squared_error: 0.7609 - val_loss: 0.7493 - val_mean_squared_error: 0.7493\n",
            "Epoch 4/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7575 - mean_squared_error: 0.7575 - val_loss: 0.7475 - val_mean_squared_error: 0.7475\n",
            "Epoch 5/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7557 - mean_squared_error: 0.7557 - val_loss: 0.7508 - val_mean_squared_error: 0.7508\n",
            "Epoch 6/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7541 - mean_squared_error: 0.7541 - val_loss: 0.7452 - val_mean_squared_error: 0.7452\n",
            "Epoch 7/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7535 - mean_squared_error: 0.7535 - val_loss: 0.7636 - val_mean_squared_error: 0.7636\n",
            "Epoch 8/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7513 - mean_squared_error: 0.7513 - val_loss: 0.7432 - val_mean_squared_error: 0.7432\n",
            "Epoch 9/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7489 - mean_squared_error: 0.7489 - val_loss: 0.7425 - val_mean_squared_error: 0.7425\n",
            "Epoch 10/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7487 - mean_squared_error: 0.7487 - val_loss: 0.7588 - val_mean_squared_error: 0.7588\n",
            "Epoch 11/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7480 - mean_squared_error: 0.7480 - val_loss: 0.7454 - val_mean_squared_error: 0.7454\n",
            "Epoch 12/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7472 - mean_squared_error: 0.7472 - val_loss: 0.7600 - val_mean_squared_error: 0.7600\n",
            "Epoch 13/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7462 - mean_squared_error: 0.7462 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
            "Epoch 14/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7455 - mean_squared_error: 0.7455 - val_loss: 0.7450 - val_mean_squared_error: 0.7450\n",
            "Epoch 15/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7451 - mean_squared_error: 0.7451 - val_loss: 0.7430 - val_mean_squared_error: 0.7430\n",
            "Epoch 16/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7442 - mean_squared_error: 0.7442 - val_loss: 0.7462 - val_mean_squared_error: 0.7462\n",
            "Epoch 17/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7440 - mean_squared_error: 0.7440 - val_loss: 0.7477 - val_mean_squared_error: 0.7477\n",
            "Epoch 18/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7441 - mean_squared_error: 0.7441 - val_loss: 0.7390 - val_mean_squared_error: 0.7390\n",
            "Epoch 19/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7433 - mean_squared_error: 0.7433 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
            "Epoch 20/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7429 - mean_squared_error: 0.7429 - val_loss: 0.7424 - val_mean_squared_error: 0.7424\n",
            "Epoch 21/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7424 - mean_squared_error: 0.7424 - val_loss: 0.7432 - val_mean_squared_error: 0.7432\n",
            "Epoch 22/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7420 - mean_squared_error: 0.7420 - val_loss: 0.7587 - val_mean_squared_error: 0.7587\n",
            "Epoch 23/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7419 - mean_squared_error: 0.7419 - val_loss: 0.7382 - val_mean_squared_error: 0.7382\n",
            "Epoch 24/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7414 - mean_squared_error: 0.7414 - val_loss: 0.7403 - val_mean_squared_error: 0.7403\n",
            "Epoch 25/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7414 - mean_squared_error: 0.7414 - val_loss: 0.7486 - val_mean_squared_error: 0.7486\n",
            "Epoch 26/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7409 - mean_squared_error: 0.7409 - val_loss: 0.7441 - val_mean_squared_error: 0.7441\n",
            "Epoch 27/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7402 - mean_squared_error: 0.7402 - val_loss: 0.7431 - val_mean_squared_error: 0.7431\n",
            "Epoch 28/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7397 - mean_squared_error: 0.7397 - val_loss: 0.7399 - val_mean_squared_error: 0.7399\n",
            "Epoch 29/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7400 - mean_squared_error: 0.7400 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 30/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7395 - mean_squared_error: 0.7395 - val_loss: 0.7432 - val_mean_squared_error: 0.7432\n",
            "Epoch 31/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7393 - mean_squared_error: 0.7393 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
            "Epoch 32/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7381 - mean_squared_error: 0.7381 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 33/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7382 - mean_squared_error: 0.7382 - val_loss: 0.7436 - val_mean_squared_error: 0.7436\n",
            "Epoch 34/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7382 - mean_squared_error: 0.7382 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
            "Epoch 35/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7390 - mean_squared_error: 0.7390 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
            "Epoch 36/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7375 - mean_squared_error: 0.7375 - val_loss: 0.7377 - val_mean_squared_error: 0.7377\n",
            "Epoch 37/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7377 - mean_squared_error: 0.7377 - val_loss: 0.7491 - val_mean_squared_error: 0.7491\n",
            "Epoch 38/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7373 - mean_squared_error: 0.7373 - val_loss: 0.7382 - val_mean_squared_error: 0.7382\n",
            "Epoch 39/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7378 - mean_squared_error: 0.7378 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
            "Epoch 40/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7372 - mean_squared_error: 0.7372 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
            "Epoch 41/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7366 - mean_squared_error: 0.7366 - val_loss: 0.7369 - val_mean_squared_error: 0.7369\n",
            "Epoch 42/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7367 - mean_squared_error: 0.7367 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 43/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7371 - mean_squared_error: 0.7371 - val_loss: 0.7372 - val_mean_squared_error: 0.7372\n",
            "Epoch 44/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7368 - mean_squared_error: 0.7368 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
            "Epoch 45/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7362 - mean_squared_error: 0.7362 - val_loss: 0.7376 - val_mean_squared_error: 0.7376\n",
            "Epoch 46/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7358 - mean_squared_error: 0.7358 - val_loss: 0.7400 - val_mean_squared_error: 0.7400\n",
            "Epoch 47/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7363 - mean_squared_error: 0.7363 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
            "Epoch 48/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7360 - mean_squared_error: 0.7360 - val_loss: 0.7387 - val_mean_squared_error: 0.7387\n",
            "Epoch 49/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7351 - mean_squared_error: 0.7351 - val_loss: 0.7366 - val_mean_squared_error: 0.7366\n",
            "Epoch 50/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7356 - mean_squared_error: 0.7356 - val_loss: 0.7375 - val_mean_squared_error: 0.7375\n",
            "Epoch 51/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7356 - mean_squared_error: 0.7356 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
            "Epoch 52/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7350 - mean_squared_error: 0.7350 - val_loss: 0.7474 - val_mean_squared_error: 0.7474\n",
            "Epoch 53/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7348 - mean_squared_error: 0.7348 - val_loss: 0.7359 - val_mean_squared_error: 0.7359\n",
            "Epoch 54/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7344 - mean_squared_error: 0.7344 - val_loss: 0.7356 - val_mean_squared_error: 0.7356\n",
            "Epoch 55/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7347 - mean_squared_error: 0.7347 - val_loss: 0.7369 - val_mean_squared_error: 0.7369\n",
            "Epoch 56/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7350 - mean_squared_error: 0.7350 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 57/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7349 - mean_squared_error: 0.7349 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
            "Epoch 58/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7343 - mean_squared_error: 0.7343 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 59/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7343 - mean_squared_error: 0.7343 - val_loss: 0.7359 - val_mean_squared_error: 0.7359\n",
            "Epoch 60/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
            "Epoch 61/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7340 - mean_squared_error: 0.7340 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
            "Epoch 62/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7368 - val_mean_squared_error: 0.7368\n",
            "Epoch 63/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7440 - val_mean_squared_error: 0.7440\n",
            "Epoch 64/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7357 - val_mean_squared_error: 0.7357\n",
            "Epoch 65/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7336 - mean_squared_error: 0.7336 - val_loss: 0.7369 - val_mean_squared_error: 0.7369\n",
            "Epoch 66/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7331 - mean_squared_error: 0.7331 - val_loss: 0.7366 - val_mean_squared_error: 0.7366\n",
            "Epoch 67/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7333 - mean_squared_error: 0.7333 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 68/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7333 - mean_squared_error: 0.7333 - val_loss: 0.7461 - val_mean_squared_error: 0.7461\n",
            "Epoch 69/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7324 - mean_squared_error: 0.7324 - val_loss: 0.7440 - val_mean_squared_error: 0.7440\n",
            "Epoch 70/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7329 - mean_squared_error: 0.7329 - val_loss: 0.7476 - val_mean_squared_error: 0.7476\n",
            "Epoch 71/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7332 - mean_squared_error: 0.7332 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
            "Epoch 72/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7326 - mean_squared_error: 0.7326 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 73/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7322 - mean_squared_error: 0.7322 - val_loss: 0.7421 - val_mean_squared_error: 0.7421\n",
            "Epoch 74/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7328 - mean_squared_error: 0.7328 - val_loss: 0.7372 - val_mean_squared_error: 0.7372\n",
            "Epoch 75/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7334 - mean_squared_error: 0.7334 - val_loss: 0.7395 - val_mean_squared_error: 0.7395\n",
            "Epoch 76/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7317 - mean_squared_error: 0.7317 - val_loss: 0.7465 - val_mean_squared_error: 0.7465\n",
            "Epoch 77/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7321 - mean_squared_error: 0.7321 - val_loss: 0.7456 - val_mean_squared_error: 0.7456\n",
            "Epoch 78/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7321 - mean_squared_error: 0.7321 - val_loss: 0.7518 - val_mean_squared_error: 0.7518\n",
            "Epoch 79/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7323 - mean_squared_error: 0.7323 - val_loss: 0.7373 - val_mean_squared_error: 0.7373\n",
            "Epoch 80/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7321 - mean_squared_error: 0.7321 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
            "Epoch 81/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7318 - mean_squared_error: 0.7318 - val_loss: 0.7383 - val_mean_squared_error: 0.7383\n",
            "Epoch 82/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7314 - mean_squared_error: 0.7314 - val_loss: 0.7416 - val_mean_squared_error: 0.7416\n",
            "Epoch 83/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7313 - mean_squared_error: 0.7313 - val_loss: 0.7368 - val_mean_squared_error: 0.7368\n",
            "Epoch 84/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7314 - mean_squared_error: 0.7314 - val_loss: 0.7514 - val_mean_squared_error: 0.7514\n",
            "Epoch 85/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7307 - mean_squared_error: 0.7307 - val_loss: 0.7376 - val_mean_squared_error: 0.7376\n",
            "Epoch 86/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7308 - mean_squared_error: 0.7308 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
            "Epoch 87/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7307 - mean_squared_error: 0.7307 - val_loss: 0.7372 - val_mean_squared_error: 0.7372\n",
            "Epoch 88/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7304 - mean_squared_error: 0.7304 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 89/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7307 - mean_squared_error: 0.7307 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
            "Epoch 90/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7308 - mean_squared_error: 0.7308 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 91/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7302 - mean_squared_error: 0.7302 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 92/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7306 - mean_squared_error: 0.7306 - val_loss: 0.7427 - val_mean_squared_error: 0.7427\n",
            "Epoch 93/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7306 - mean_squared_error: 0.7306 - val_loss: 0.7369 - val_mean_squared_error: 0.7369\n",
            "Epoch 94/100\n",
            "6563/6563 [==============================] - 38s 6ms/step - loss: 0.7305 - mean_squared_error: 0.7305 - val_loss: 0.7617 - val_mean_squared_error: 0.7617\n",
            "Epoch 95/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7297 - mean_squared_error: 0.7297 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 96/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7299 - mean_squared_error: 0.7299 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
            "Epoch 97/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7300 - mean_squared_error: 0.7300 - val_loss: 0.7470 - val_mean_squared_error: 0.7470\n",
            "Epoch 98/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7294 - mean_squared_error: 0.7294 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
            "Epoch 99/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7297 - mean_squared_error: 0.7297 - val_loss: 0.7407 - val_mean_squared_error: 0.7407\n",
            "Epoch 100/100\n",
            "6563/6563 [==============================] - 39s 6ms/step - loss: 0.7293 - mean_squared_error: 0.7293 - val_loss: 0.7424 - val_mean_squared_error: 0.7424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdfeANqUuZp_",
        "outputId": "6080df89-5a1a-4e61-e8d0-90753b100981"
      },
      "source": [
        "y_pred = model.predict(X_valid,batch_size = 64)\n",
        "print(y_pred.shape,y_valid.shape)\n",
        "model.evaluate(x=X_valid,y=y_valid,batch_size=64,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90000, 1) (90000,)\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.7424 - mean_squared_error: 0.7424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7424416542053223, 0.7424416542053223]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "8mgQnAuoroui",
        "outputId": "c8959974-8a6f-485e-a39d-49a8d920b946"
      },
      "source": [
        "sub = pd.read_csv(filepath+'sample_submission.csv')\n",
        "y_pred = model.predict(X_test,batch_size=32)\n",
        "sub['target'] = y_pred\n",
        "sub.to_csv(filepath+'deep_1.csv', index =False)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.481535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>7.865315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>7.617304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>7.410262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>7.168121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    target\n",
              "0   0  7.481535\n",
              "1   5  7.865315\n",
              "2  15  7.617304\n",
              "3  16  7.410262\n",
              "4  17  7.168121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-TamZxU6KNT"
      },
      "source": [
        "# 2. 유닛을 똑같이 줌\n",
        "activ_ = 'relu'\n",
        "h_units = 36\n",
        "n_inputs=24\n",
        "def dnn_model():\n",
        "  model=Sequential()\n",
        "  #hidden layer #1\n",
        "  model.add(Dense(units = h_units , input_dim = n_inputs))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #2\n",
        "  model.add(Dense(units = h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #3\n",
        "  model.add(Dense(units =h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #4\n",
        "  model.add(Dense(units =h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #5\n",
        "  model.add(Dense(units = h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #6\n",
        "  model.add(Dense(units =h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #hidden layer #7\n",
        "  model.add(Dense(units = h_units))\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #output layer\n",
        "  model.add(Dense(units = 1))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfXNoI-sKPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9a1817-f764-49ce-e90a-0c95e14bd4fd"
      },
      "source": [
        "model =dnn_model()\n",
        "model.summary()\n",
        "opti = tf.keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(optimizer = opti,loss = 'mean_squared_error',metrics=[tf.keras.metrics.MeanSquaredError()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 36)                900       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 36)                144       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 36)                144       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 36)                144       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 36)                144       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 36)                144       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 36)                144       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 36)                1332      \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 37        \n",
            "=================================================================\n",
            "Total params: 9,793\n",
            "Trainable params: 9,361\n",
            "Non-trainable params: 432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3d4Er6cxbr5",
        "outputId": "2b931f2d-6250-48ce-cc96-49fa0bb24200"
      },
      "source": [
        "hist = model.fit(X_train, y_train, epochs=100, verbose=True,batch_size=64, validation_data=(X_valid,y_valid),shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3282/3282 [==============================] - 20s 6ms/step - loss: 1.5325 - mean_squared_error: 1.5325 - val_loss: 0.8149 - val_mean_squared_error: 0.8149\n",
            "Epoch 2/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7910 - mean_squared_error: 0.7910 - val_loss: 0.8093 - val_mean_squared_error: 0.8093\n",
            "Epoch 3/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7720 - mean_squared_error: 0.7720 - val_loss: 0.7546 - val_mean_squared_error: 0.7546\n",
            "Epoch 4/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7618 - mean_squared_error: 0.7618 - val_loss: 0.7684 - val_mean_squared_error: 0.7684\n",
            "Epoch 5/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7579 - mean_squared_error: 0.7579 - val_loss: 0.7650 - val_mean_squared_error: 0.7650\n",
            "Epoch 6/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7573 - mean_squared_error: 0.7573 - val_loss: 0.7476 - val_mean_squared_error: 0.7476\n",
            "Epoch 7/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7506 - mean_squared_error: 0.7506 - val_loss: 0.7518 - val_mean_squared_error: 0.7518\n",
            "Epoch 8/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7506 - mean_squared_error: 0.7506 - val_loss: 0.7907 - val_mean_squared_error: 0.7907\n",
            "Epoch 9/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7504 - mean_squared_error: 0.7504 - val_loss: 0.7541 - val_mean_squared_error: 0.7541\n",
            "Epoch 10/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7506 - mean_squared_error: 0.7506 - val_loss: 0.7652 - val_mean_squared_error: 0.7652\n",
            "Epoch 11/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7497 - mean_squared_error: 0.7497 - val_loss: 0.7465 - val_mean_squared_error: 0.7465\n",
            "Epoch 12/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7471 - mean_squared_error: 0.7471 - val_loss: 0.7498 - val_mean_squared_error: 0.7498\n",
            "Epoch 13/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7535 - mean_squared_error: 0.7535 - val_loss: 0.7450 - val_mean_squared_error: 0.7450\n",
            "Epoch 14/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7473 - mean_squared_error: 0.7473 - val_loss: 0.7460 - val_mean_squared_error: 0.7460\n",
            "Epoch 15/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7482 - mean_squared_error: 0.7482 - val_loss: 0.7452 - val_mean_squared_error: 0.7452\n",
            "Epoch 16/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7513 - mean_squared_error: 0.7513 - val_loss: 0.7463 - val_mean_squared_error: 0.7463\n",
            "Epoch 17/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7418 - mean_squared_error: 0.7418 - val_loss: 0.7445 - val_mean_squared_error: 0.7445\n",
            "Epoch 18/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7493 - mean_squared_error: 0.7493 - val_loss: 0.7459 - val_mean_squared_error: 0.7459\n",
            "Epoch 19/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7491 - mean_squared_error: 0.7491 - val_loss: 0.7571 - val_mean_squared_error: 0.7571\n",
            "Epoch 20/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7455 - mean_squared_error: 0.7455 - val_loss: 0.7438 - val_mean_squared_error: 0.7438\n",
            "Epoch 21/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7460 - mean_squared_error: 0.7460 - val_loss: 0.7462 - val_mean_squared_error: 0.7462\n",
            "Epoch 22/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7450 - mean_squared_error: 0.7450 - val_loss: 0.7419 - val_mean_squared_error: 0.7419\n",
            "Epoch 23/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7498 - mean_squared_error: 0.7498 - val_loss: 0.7479 - val_mean_squared_error: 0.7479\n",
            "Epoch 24/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7474 - mean_squared_error: 0.7474 - val_loss: 0.7629 - val_mean_squared_error: 0.7629\n",
            "Epoch 25/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7425 - mean_squared_error: 0.7425 - val_loss: 0.7468 - val_mean_squared_error: 0.7468\n",
            "Epoch 26/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7465 - mean_squared_error: 0.7465 - val_loss: 0.7455 - val_mean_squared_error: 0.7455\n",
            "Epoch 27/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7439 - mean_squared_error: 0.7439 - val_loss: 0.7433 - val_mean_squared_error: 0.7433\n",
            "Epoch 28/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7410 - mean_squared_error: 0.7410 - val_loss: 0.7417 - val_mean_squared_error: 0.7417\n",
            "Epoch 29/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7446 - mean_squared_error: 0.7446 - val_loss: 0.7570 - val_mean_squared_error: 0.7570\n",
            "Epoch 30/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7432 - mean_squared_error: 0.7432 - val_loss: 0.7480 - val_mean_squared_error: 0.7480\n",
            "Epoch 31/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7413 - mean_squared_error: 0.7413 - val_loss: 0.7424 - val_mean_squared_error: 0.7424\n",
            "Epoch 32/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7415 - mean_squared_error: 0.7415 - val_loss: 0.7480 - val_mean_squared_error: 0.7480\n",
            "Epoch 33/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7390 - mean_squared_error: 0.7390 - val_loss: 0.7492 - val_mean_squared_error: 0.7492\n",
            "Epoch 34/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7451 - mean_squared_error: 0.7451 - val_loss: 0.7395 - val_mean_squared_error: 0.7395\n",
            "Epoch 35/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7425 - mean_squared_error: 0.7425 - val_loss: 0.7434 - val_mean_squared_error: 0.7434\n",
            "Epoch 36/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7421 - mean_squared_error: 0.7421 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
            "Epoch 37/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7400 - mean_squared_error: 0.7400 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
            "Epoch 38/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7416 - mean_squared_error: 0.7416 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
            "Epoch 39/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7406 - mean_squared_error: 0.7406 - val_loss: 0.7397 - val_mean_squared_error: 0.7397\n",
            "Epoch 40/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7434 - mean_squared_error: 0.7434 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
            "Epoch 41/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7443 - mean_squared_error: 0.7443 - val_loss: 0.7441 - val_mean_squared_error: 0.7441\n",
            "Epoch 42/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7408 - mean_squared_error: 0.7408 - val_loss: 0.7531 - val_mean_squared_error: 0.7531\n",
            "Epoch 43/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7412 - mean_squared_error: 0.7412 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 44/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7403 - mean_squared_error: 0.7403 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
            "Epoch 45/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7363 - mean_squared_error: 0.7363 - val_loss: 0.7395 - val_mean_squared_error: 0.7395\n",
            "Epoch 46/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7419 - mean_squared_error: 0.7419 - val_loss: 0.7418 - val_mean_squared_error: 0.7418\n",
            "Epoch 47/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7398 - mean_squared_error: 0.7398 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
            "Epoch 48/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7355 - mean_squared_error: 0.7355 - val_loss: 0.7408 - val_mean_squared_error: 0.7408\n",
            "Epoch 49/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7409 - mean_squared_error: 0.7409 - val_loss: 0.7457 - val_mean_squared_error: 0.7457\n",
            "Epoch 50/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7371 - mean_squared_error: 0.7371 - val_loss: 0.7413 - val_mean_squared_error: 0.7413\n",
            "Epoch 51/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7368 - mean_squared_error: 0.7368 - val_loss: 0.7435 - val_mean_squared_error: 0.7435\n",
            "Epoch 52/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7386 - mean_squared_error: 0.7386 - val_loss: 0.7465 - val_mean_squared_error: 0.7465\n",
            "Epoch 53/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7373 - mean_squared_error: 0.7373 - val_loss: 0.7389 - val_mean_squared_error: 0.7389\n",
            "Epoch 54/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7379 - mean_squared_error: 0.7379 - val_loss: 0.7469 - val_mean_squared_error: 0.7469\n",
            "Epoch 55/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7387 - mean_squared_error: 0.7387 - val_loss: 0.7389 - val_mean_squared_error: 0.7389\n",
            "Epoch 56/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7356 - mean_squared_error: 0.7356 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
            "Epoch 57/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7402 - mean_squared_error: 0.7402 - val_loss: 0.7395 - val_mean_squared_error: 0.7395\n",
            "Epoch 58/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7406 - mean_squared_error: 0.7406 - val_loss: 0.7416 - val_mean_squared_error: 0.7416\n",
            "Epoch 59/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7385 - mean_squared_error: 0.7385 - val_loss: 0.7482 - val_mean_squared_error: 0.7482\n",
            "Epoch 60/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7369 - mean_squared_error: 0.7369 - val_loss: 0.7386 - val_mean_squared_error: 0.7386\n",
            "Epoch 61/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7397 - mean_squared_error: 0.7397 - val_loss: 0.7431 - val_mean_squared_error: 0.7431\n",
            "Epoch 62/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7370 - mean_squared_error: 0.7370 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
            "Epoch 63/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7358 - mean_squared_error: 0.7358 - val_loss: 0.7415 - val_mean_squared_error: 0.7415\n",
            "Epoch 64/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7371 - mean_squared_error: 0.7371 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 65/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7393 - mean_squared_error: 0.7393 - val_loss: 0.7450 - val_mean_squared_error: 0.7450\n",
            "Epoch 66/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7389 - mean_squared_error: 0.7389 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
            "Epoch 67/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7368 - mean_squared_error: 0.7368 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
            "Epoch 68/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7369 - mean_squared_error: 0.7369 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
            "Epoch 69/100\n",
            "3282/3282 [==============================] - 20s 6ms/step - loss: 0.7342 - mean_squared_error: 0.7342 - val_loss: 0.7509 - val_mean_squared_error: 0.7509\n",
            "Epoch 70/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7361 - mean_squared_error: 0.7361 - val_loss: 0.7409 - val_mean_squared_error: 0.7409\n",
            "Epoch 71/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7340 - mean_squared_error: 0.7340 - val_loss: 0.7382 - val_mean_squared_error: 0.7382\n",
            "Epoch 72/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7352 - mean_squared_error: 0.7352 - val_loss: 0.7376 - val_mean_squared_error: 0.7376\n",
            "Epoch 73/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7343 - mean_squared_error: 0.7343 - val_loss: 0.7438 - val_mean_squared_error: 0.7438\n",
            "Epoch 74/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7391 - mean_squared_error: 0.7391 - val_loss: 0.7422 - val_mean_squared_error: 0.7422\n",
            "Epoch 75/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7398 - mean_squared_error: 0.7398 - val_loss: 0.7458 - val_mean_squared_error: 0.7458\n",
            "Epoch 76/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7371 - mean_squared_error: 0.7371 - val_loss: 0.7386 - val_mean_squared_error: 0.7386\n",
            "Epoch 77/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7322 - mean_squared_error: 0.7322 - val_loss: 0.7421 - val_mean_squared_error: 0.7421\n",
            "Epoch 78/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7343 - mean_squared_error: 0.7343 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 79/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7329 - mean_squared_error: 0.7329 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
            "Epoch 80/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7358 - mean_squared_error: 0.7358 - val_loss: 0.7437 - val_mean_squared_error: 0.7437\n",
            "Epoch 81/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7362 - mean_squared_error: 0.7362 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
            "Epoch 82/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7347 - mean_squared_error: 0.7347 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
            "Epoch 83/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7385 - mean_squared_error: 0.7385 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 84/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7345 - mean_squared_error: 0.7345 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 85/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7358 - mean_squared_error: 0.7358 - val_loss: 0.7441 - val_mean_squared_error: 0.7441\n",
            "Epoch 86/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7389 - mean_squared_error: 0.7389 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 87/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7355 - mean_squared_error: 0.7355 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 88/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7363 - mean_squared_error: 0.7363 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
            "Epoch 89/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7354 - mean_squared_error: 0.7354 - val_loss: 0.7395 - val_mean_squared_error: 0.7395\n",
            "Epoch 90/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7357 - mean_squared_error: 0.7357 - val_loss: 0.7423 - val_mean_squared_error: 0.7423\n",
            "Epoch 91/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7359 - mean_squared_error: 0.7359 - val_loss: 0.7449 - val_mean_squared_error: 0.7449\n",
            "Epoch 92/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7363 - mean_squared_error: 0.7363 - val_loss: 0.7399 - val_mean_squared_error: 0.7399\n",
            "Epoch 93/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7382 - mean_squared_error: 0.7382 - val_loss: 0.7401 - val_mean_squared_error: 0.7401\n",
            "Epoch 94/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7363 - mean_squared_error: 0.7363 - val_loss: 0.7383 - val_mean_squared_error: 0.7383\n",
            "Epoch 95/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7382 - mean_squared_error: 0.7382 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 96/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7356 - mean_squared_error: 0.7356 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 97/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7347 - mean_squared_error: 0.7347 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
            "Epoch 98/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7380 - mean_squared_error: 0.7380 - val_loss: 0.7372 - val_mean_squared_error: 0.7372\n",
            "Epoch 99/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7369 - mean_squared_error: 0.7369 - val_loss: 0.7422 - val_mean_squared_error: 0.7422\n",
            "Epoch 100/100\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.7320 - mean_squared_error: 0.7320 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMXdatZ-xz18",
        "outputId": "25823826-b559-42a7-b22f-3ac7ddf97072"
      },
      "source": [
        "y_pred = model.predict(X_valid,batch_size = 64)\n",
        "print(y_pred.shape,y_valid.shape)\n",
        "model.evaluate(x=X_valid,y=y_valid,batch_size=64,verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90000, 1) (90000,)\n",
            "1407/1407 [==============================] - 3s 2ms/step - loss: 0.7405 - mean_squared_error: 0.7405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7404606938362122, 0.7404606938362122]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j99F8jvwJmjm"
      },
      "source": [
        "# 유닛을 32개 더 줌\n",
        "activ_ = 'relu'\n",
        "h_units = 64\n",
        "n_inputs=24\n",
        "\n",
        "def dnn_model():\n",
        "  model=Sequential()\n",
        "\n",
        "  #hidden layer #1\n",
        "  model.add(Dense(units = h_units , input_dim = n_inputs))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #2\n",
        "  model.add(Dense(units = h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "  #hidden layer #3\n",
        "  model.add(Dense(units =h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #hidden layer #4\n",
        "  model.add(Dense(units =h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "    #hidden layer #5\n",
        "  model.add(Dense(units = h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #hidden layer #6\n",
        "  model.add(Dense(units =h_units ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #hidden layer #7\n",
        "  model.add(Dense(units = h_units))\n",
        "  model.add(Activation(activ_))\n",
        "\n",
        "  #output layer\n",
        "  model.add(Dense(units = 1))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K6S_Y4QJxcd",
        "outputId": "427e45e4-6857-4ef5-f642-5379823d551f"
      },
      "source": [
        "model =dnn_model()\n",
        "model.summary()\n",
        "opti = tf.keras.optimizers.Adam(lr=0.01)\n",
        "model.compile(optimizer = opti,loss = 'mean_squared_error',metrics=[tf.keras.metrics.MeanSquaredError()])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_32 (Dense)             (None, 64)                1600      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 28,161\n",
            "Trainable params: 27,393\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m70xnoRIa92b",
        "outputId": "36c5afea-7b39-45d2-bc09-fa913eacd618"
      },
      "source": [
        "hist = model.fit(X_train, y_train, epochs=100, verbose=True,batch_size=64, validation_data=(X_valid,y_valid),shuffle=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3282/3282 [==============================] - 10s 3ms/step - loss: 1.2777 - mean_squared_error: 1.2777 - val_loss: 0.8847 - val_mean_squared_error: 0.8847\n",
            "Epoch 2/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7953 - mean_squared_error: 0.7953 - val_loss: 0.7535 - val_mean_squared_error: 0.7535\n",
            "Epoch 3/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7681 - mean_squared_error: 0.7681 - val_loss: 0.7539 - val_mean_squared_error: 0.7539\n",
            "Epoch 4/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7618 - mean_squared_error: 0.7618 - val_loss: 0.7536 - val_mean_squared_error: 0.7536\n",
            "Epoch 5/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7539 - mean_squared_error: 0.7539 - val_loss: 0.7469 - val_mean_squared_error: 0.7469\n",
            "Epoch 6/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7510 - mean_squared_error: 0.7510 - val_loss: 0.7554 - val_mean_squared_error: 0.7554\n",
            "Epoch 7/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7540 - mean_squared_error: 0.7540 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
            "Epoch 8/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7509 - mean_squared_error: 0.7509 - val_loss: 0.7432 - val_mean_squared_error: 0.7432\n",
            "Epoch 9/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7494 - mean_squared_error: 0.7494 - val_loss: 0.7508 - val_mean_squared_error: 0.7508\n",
            "Epoch 10/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7506 - mean_squared_error: 0.7506 - val_loss: 0.7478 - val_mean_squared_error: 0.7478\n",
            "Epoch 11/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7482 - mean_squared_error: 0.7482 - val_loss: 0.7478 - val_mean_squared_error: 0.7478\n",
            "Epoch 12/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7465 - mean_squared_error: 0.7465 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
            "Epoch 13/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7448 - mean_squared_error: 0.7448 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
            "Epoch 14/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7443 - mean_squared_error: 0.7443 - val_loss: 0.7432 - val_mean_squared_error: 0.7432\n",
            "Epoch 15/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7426 - mean_squared_error: 0.7426 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
            "Epoch 16/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7469 - mean_squared_error: 0.7469 - val_loss: 0.7453 - val_mean_squared_error: 0.7453\n",
            "Epoch 17/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7473 - mean_squared_error: 0.7473 - val_loss: 0.7406 - val_mean_squared_error: 0.7406\n",
            "Epoch 18/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7424 - mean_squared_error: 0.7424 - val_loss: 0.7420 - val_mean_squared_error: 0.7420\n",
            "Epoch 19/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7426 - mean_squared_error: 0.7426 - val_loss: 0.7511 - val_mean_squared_error: 0.7511\n",
            "Epoch 20/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7419 - mean_squared_error: 0.7419 - val_loss: 0.7423 - val_mean_squared_error: 0.7423\n",
            "Epoch 21/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7424 - mean_squared_error: 0.7424 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
            "Epoch 22/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7409 - mean_squared_error: 0.7409 - val_loss: 0.7455 - val_mean_squared_error: 0.7455\n",
            "Epoch 23/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7429 - mean_squared_error: 0.7429 - val_loss: 0.7396 - val_mean_squared_error: 0.7396\n",
            "Epoch 24/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7414 - mean_squared_error: 0.7414 - val_loss: 0.7416 - val_mean_squared_error: 0.7416\n",
            "Epoch 25/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7403 - mean_squared_error: 0.7403 - val_loss: 0.7393 - val_mean_squared_error: 0.7393\n",
            "Epoch 26/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7397 - mean_squared_error: 0.7397 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
            "Epoch 27/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7407 - mean_squared_error: 0.7407 - val_loss: 0.7413 - val_mean_squared_error: 0.7413\n",
            "Epoch 28/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7389 - mean_squared_error: 0.7389 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
            "Epoch 29/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7419 - mean_squared_error: 0.7419 - val_loss: 0.7440 - val_mean_squared_error: 0.7440\n",
            "Epoch 30/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7415 - mean_squared_error: 0.7415 - val_loss: 0.7370 - val_mean_squared_error: 0.7370\n",
            "Epoch 31/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7399 - mean_squared_error: 0.7399 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
            "Epoch 32/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7400 - mean_squared_error: 0.7400 - val_loss: 0.7479 - val_mean_squared_error: 0.7479\n",
            "Epoch 33/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7385 - mean_squared_error: 0.7385 - val_loss: 0.7373 - val_mean_squared_error: 0.7373\n",
            "Epoch 34/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7375 - mean_squared_error: 0.7375 - val_loss: 0.7409 - val_mean_squared_error: 0.7409\n",
            "Epoch 35/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7383 - mean_squared_error: 0.7383 - val_loss: 0.7408 - val_mean_squared_error: 0.7408\n",
            "Epoch 36/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7339 - mean_squared_error: 0.7339 - val_loss: 0.7401 - val_mean_squared_error: 0.7401\n",
            "Epoch 37/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7341 - mean_squared_error: 0.7341 - val_loss: 0.7425 - val_mean_squared_error: 0.7425\n",
            "Epoch 38/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7385 - mean_squared_error: 0.7385 - val_loss: 0.7447 - val_mean_squared_error: 0.7447\n",
            "Epoch 39/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7368 - mean_squared_error: 0.7368 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
            "Epoch 40/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7339 - mean_squared_error: 0.7339 - val_loss: 0.7434 - val_mean_squared_error: 0.7434\n",
            "Epoch 41/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7345 - mean_squared_error: 0.7345 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
            "Epoch 42/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7374 - mean_squared_error: 0.7374 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
            "Epoch 43/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7360 - mean_squared_error: 0.7360 - val_loss: 0.7383 - val_mean_squared_error: 0.7383\n",
            "Epoch 44/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7370 - mean_squared_error: 0.7370 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
            "Epoch 45/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7342 - mean_squared_error: 0.7342 - val_loss: 0.7432 - val_mean_squared_error: 0.7432\n",
            "Epoch 46/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7349 - mean_squared_error: 0.7349 - val_loss: 0.7375 - val_mean_squared_error: 0.7375\n",
            "Epoch 47/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7361 - mean_squared_error: 0.7361 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 48/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7336 - mean_squared_error: 0.7336 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 49/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7399 - mean_squared_error: 0.7399 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
            "Epoch 50/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7357 - mean_squared_error: 0.7357 - val_loss: 0.7411 - val_mean_squared_error: 0.7411\n",
            "Epoch 51/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7347 - mean_squared_error: 0.7347 - val_loss: 0.7433 - val_mean_squared_error: 0.7433\n",
            "Epoch 52/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7335 - mean_squared_error: 0.7335 - val_loss: 0.7403 - val_mean_squared_error: 0.7403\n",
            "Epoch 53/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7360 - mean_squared_error: 0.7360 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
            "Epoch 54/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7348 - mean_squared_error: 0.7348 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 55/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7336 - mean_squared_error: 0.7336 - val_loss: 0.7385 - val_mean_squared_error: 0.7385\n",
            "Epoch 56/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7339 - mean_squared_error: 0.7339 - val_loss: 0.7412 - val_mean_squared_error: 0.7412\n",
            "Epoch 57/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7384 - mean_squared_error: 0.7384 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
            "Epoch 58/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7356 - mean_squared_error: 0.7356 - val_loss: 0.7373 - val_mean_squared_error: 0.7373\n",
            "Epoch 59/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7345 - mean_squared_error: 0.7345 - val_loss: 0.7404 - val_mean_squared_error: 0.7404\n",
            "Epoch 60/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7334 - mean_squared_error: 0.7334 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 61/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7362 - mean_squared_error: 0.7362 - val_loss: 0.7409 - val_mean_squared_error: 0.7409\n",
            "Epoch 62/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7324 - mean_squared_error: 0.7324 - val_loss: 0.7386 - val_mean_squared_error: 0.7386\n",
            "Epoch 63/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7367 - mean_squared_error: 0.7367 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
            "Epoch 64/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7354 - mean_squared_error: 0.7354 - val_loss: 0.7367 - val_mean_squared_error: 0.7367\n",
            "Epoch 65/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7384 - mean_squared_error: 0.7384 - val_loss: 0.7497 - val_mean_squared_error: 0.7497\n",
            "Epoch 66/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7332 - mean_squared_error: 0.7332 - val_loss: 0.7364 - val_mean_squared_error: 0.7364\n",
            "Epoch 67/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7354 - mean_squared_error: 0.7354 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 68/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7331 - mean_squared_error: 0.7331 - val_loss: 0.7387 - val_mean_squared_error: 0.7387\n",
            "Epoch 69/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7348 - mean_squared_error: 0.7348 - val_loss: 0.7398 - val_mean_squared_error: 0.7398\n",
            "Epoch 70/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 71/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7328 - mean_squared_error: 0.7328 - val_loss: 0.7378 - val_mean_squared_error: 0.7378\n",
            "Epoch 72/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7311 - mean_squared_error: 0.7311 - val_loss: 0.7410 - val_mean_squared_error: 0.7410\n",
            "Epoch 73/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7317 - mean_squared_error: 0.7317 - val_loss: 0.7375 - val_mean_squared_error: 0.7375\n",
            "Epoch 74/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7332 - mean_squared_error: 0.7332 - val_loss: 0.7455 - val_mean_squared_error: 0.7455\n",
            "Epoch 75/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7350 - mean_squared_error: 0.7350 - val_loss: 0.7392 - val_mean_squared_error: 0.7392\n",
            "Epoch 76/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7349 - mean_squared_error: 0.7349 - val_loss: 0.7374 - val_mean_squared_error: 0.7374\n",
            "Epoch 77/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7334 - mean_squared_error: 0.7334 - val_loss: 0.7370 - val_mean_squared_error: 0.7370\n",
            "Epoch 78/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7350 - mean_squared_error: 0.7350 - val_loss: 0.7386 - val_mean_squared_error: 0.7386\n",
            "Epoch 79/100\n",
            "3282/3282 [==============================] - 8s 3ms/step - loss: 0.7322 - mean_squared_error: 0.7322 - val_loss: 0.7377 - val_mean_squared_error: 0.7377\n",
            "Epoch 80/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7301 - mean_squared_error: 0.7301 - val_loss: 0.7381 - val_mean_squared_error: 0.7381\n",
            "Epoch 81/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7426 - val_mean_squared_error: 0.7426\n",
            "Epoch 82/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7308 - mean_squared_error: 0.7308 - val_loss: 0.7376 - val_mean_squared_error: 0.7376\n",
            "Epoch 83/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7361 - mean_squared_error: 0.7361 - val_loss: 0.7384 - val_mean_squared_error: 0.7384\n",
            "Epoch 84/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7338 - mean_squared_error: 0.7338 - val_loss: 0.7405 - val_mean_squared_error: 0.7405\n",
            "Epoch 85/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7329 - mean_squared_error: 0.7329 - val_loss: 0.7427 - val_mean_squared_error: 0.7427\n",
            "Epoch 86/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7319 - mean_squared_error: 0.7319 - val_loss: 0.7408 - val_mean_squared_error: 0.7408\n",
            "Epoch 87/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7356 - mean_squared_error: 0.7356 - val_loss: 0.7417 - val_mean_squared_error: 0.7417\n",
            "Epoch 88/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7315 - mean_squared_error: 0.7315 - val_loss: 0.7373 - val_mean_squared_error: 0.7373\n",
            "Epoch 89/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7283 - mean_squared_error: 0.7283 - val_loss: 0.7418 - val_mean_squared_error: 0.7418\n",
            "Epoch 90/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7343 - mean_squared_error: 0.7343 - val_loss: 0.7402 - val_mean_squared_error: 0.7402\n",
            "Epoch 91/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7331 - mean_squared_error: 0.7331 - val_loss: 0.7390 - val_mean_squared_error: 0.7390\n",
            "Epoch 92/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7326 - mean_squared_error: 0.7326 - val_loss: 0.7400 - val_mean_squared_error: 0.7400\n",
            "Epoch 93/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7350 - mean_squared_error: 0.7350 - val_loss: 0.7513 - val_mean_squared_error: 0.7513\n",
            "Epoch 94/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7345 - mean_squared_error: 0.7345 - val_loss: 0.7417 - val_mean_squared_error: 0.7417\n",
            "Epoch 95/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7349 - mean_squared_error: 0.7349 - val_loss: 0.7391 - val_mean_squared_error: 0.7391\n",
            "Epoch 96/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7340 - mean_squared_error: 0.7340 - val_loss: 0.7561 - val_mean_squared_error: 0.7561\n",
            "Epoch 97/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7368 - mean_squared_error: 0.7368 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
            "Epoch 98/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7340 - mean_squared_error: 0.7340 - val_loss: 0.7551 - val_mean_squared_error: 0.7551\n",
            "Epoch 99/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7351 - mean_squared_error: 0.7351 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
            "Epoch 100/100\n",
            "3282/3282 [==============================] - 9s 3ms/step - loss: 0.7290 - mean_squared_error: 0.7290 - val_loss: 0.7372 - val_mean_squared_error: 0.7372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PQ5PWcBbDTQ",
        "outputId": "198c378f-b199-4e5d-c635-1e812c50b598"
      },
      "source": [
        "y_pred = model.predict(X_valid,batch_size = 64)\n",
        "print(y_pred.shape,y_valid.shape)\n",
        "model.evaluate(x=X_valid,y=y_valid,batch_size=64,verbose=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90000, 1) (90000,)\n",
            "1407/1407 [==============================] - 1s 867us/step - loss: 0.7372 - mean_squared_error: 0.7372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7372406125068665, 0.7372406125068665]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "-j6ZZ6bnnsBB",
        "outputId": "5f97a30b-c5ef-4910-c76c-ae504c85a26c"
      },
      "source": [
        "sub = pd.read_csv(filepath+'sample_submission.csv')\n",
        "y_pred = model.predict(X_test,batch_size=32)\n",
        "sub['target'] = y_pred\n",
        "sub.to_csv(filepath+'deep_learning.csv', index =False)\n",
        "sub.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7.481429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>7.866292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>7.582352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>7.337811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>7.118035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    target\n",
              "0   0  7.481429\n",
              "1   5  7.866292\n",
              "2  15  7.582352\n",
              "3  16  7.337811\n",
              "4  17  7.118035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}